{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prony series identification for linear viscoelastic material models\n",
    "Martin Springer | 2022 v0.1 \n",
    "\n",
    "***\n",
    "\n",
    "\n",
    "## Theory of linear viscoelasticity\n",
    "\n",
    "Theory of linear [viscoelasticity](https://en.wikipedia.org/wiki/Viscoelasticity) is used to describe the mechanical response of polymer materials under small strain conditions. An extensive review can be found in [Brinson H. F., Brinson L. C,. Polymer Engineering Science and Viscoelasticity,\n",
    "Springer, (2015)](https://link.springer.com/book/10.1007/978-1-4899-7485-3). A brief summary is provided below outlining the equations used in this notebook. The summary was extracted from [Springer, M., and Bosco N. Prog Photovolt 28.7 (2020): 659-681](https://onlinelibrary.wiley.com/doi/full/10.1002/pip.3257). <br/><br/>\n",
    "   \n",
    "\n",
    "\n",
    "  ### Mathematical description\n",
    "  \n",
    "  The rate-dependent material behavior can be described in either the time or frequency domain. In the time domain, the uniaxial, nonaging, isothermal stress-strain equation for a linear viscoelastic material can be represented by a Boltzmann superposition integral,\n",
    "  \n",
    "  \\begin{equation}\n",
    "  \\sigma(t) = \\int_0^t E(t-\\tau) \\frac{\\mathrm{d \\varepsilon(\\tau)}}{\\mathrm{d} \\tau} \\mathrm{d} \\tau \\quad ,\n",
    "  \\end{equation}\n",
    "  \n",
    "  where $\\sigma(t)$ is the stress response over time, $t$; $E(t)$ is the relaxation modulus; $\\varepsilon$ denotes the strain; and $\\tau$ is the integration variable. The limiting moduli for the viscoelastic material are defined as the instantaneous modulus, $E(t=0) = E_0$, and the equilibrium modulus, i.e., $E(t) \\rightarrow E_{\\infty}$ for $t \\rightarrow \\infty$. \n",
    "  \n",
    "  The [Generalized Maxwell Model](https://en.wikipedia.org/wiki/Generalized_Maxwell_model) is commonly used to represent the stress-strain response of polymers. The relaxation modulus derived from this model is given by,\n",
    "  \n",
    "  \\begin{equation}\n",
    "  E(t) = E_{\\infty} + \\sum\\limits_{i=1}^{m} E_i \\exp\\left(-\\frac{t}{\\tau_i} \\right) \\quad ,\n",
    "  \\label{eq:RelProny}\n",
    "  \\end{equation}\n",
    "  \n",
    "  where $\\tau_i$ (relaxation times),  $E_i = E_0 \\alpha_i$ (relaxation moduli) are material properties, and $m$ is the number of terms in the series. The above equation is often referred to as Prony series, and the equilibrium modulus can be defined by the Prony series as,\n",
    "  \n",
    "  \\begin{equation}\n",
    "  \tE_{\\infty} = E_0 \\left[1-\\sum_{i=1}^N \\alpha_i \\right] \\quad .\n",
    "  \\end{equation}\n",
    "  \n",
    "  The material properties can be directly obtained from relaxation or frequency-dependent test data. Material properties measured in the time domain can be converted into the frequency domain, and vice versa, by making use of a Fourier transformation,\n",
    "  \n",
    "  \\begin{align}\n",
    "  E'(\\omega) &= E_{\\infty} + \\sum\\limits_{i=1}^{m}\\frac{\\omega^2 \\tau_i^2 E_i}{\\omega^2 \\tau_i^2 + 1} \\quad ,\n",
    "  \\label{eq:PronyStor} \\\\\n",
    "  E''(\\omega) &= \\sum\\limits_{i=1}^{m} \\frac{\\omega \\tau_i E_i}{\\omega^2 \\tau_i^2 +1} \\quad .\n",
    "  \\label{eq:PronyLoss}\n",
    "  \\end{align}\n",
    "  \n",
    "  Herein, $E'(\\omega)$ is the storage modulus, $E''(\\omega)$ is the loss modulus, and $\\omega = 2 \\pi f$ is the angular frequency, where $f=1/t$ is the frequency in Hertz and $t$ is the time period in seconds, respectively. The complex modulus, $E^*(\\omega)$, and the loss factor, $\\tan(\\delta)$, are given as,\n",
    "  \n",
    "  \\begin{align}\n",
    "  E^*(\\omega) &= E'(\\omega)  + i E''(\\omega) \\quad \\text{and} \\\\\n",
    "  \\tan(\\delta)  & =  \\frac{E''(\\omega)}{E'(\\omega)} \\quad ,\n",
    "  \\end{align}\n",
    "  \n",
    "  respectively.\n",
    "  \n",
    "  ### Experimental characterization\n",
    "  \n",
    "  An efficient way to determine the storage modulus, $E'(\\omega)$, and the loss modulus, $E''(\\omega)$, is by dynamic mechanical analysis (DMA) or dynamic mechanical thermal analysis (DMTA). The material under test is excited to mechanical steady-state oscillations, either load- or displacement-controlled, and the corresponding response is measured. Alternatively, relaxation experiments in the time domain can be conducted to determine the relaxation modulus, $E(t)$.\n",
    "  \n",
    "  Measurements at very low frequencies (long time periods) can be very time-consuming and might be unfeasible for practical applications. On the other side of the spectrum, measurements at very high frequencies can be limited by the instrumentation or unintended heating of the sample during cyclic deformation. To avoid such situations, the [time-temperature superposition principle (TTSP)](https://en.wikipedia.org/wiki/Time%E2%80%93temperature_superposition) is applied for thermo-rheologically simple materials. For such materials, the viscoelastic response at one temperature is related to the viscoelastic response at another temperature by changing the time scale (or frequency). This way, the time scale for the materials characterization can be extended by conducting the same frequency measurements at different temperatures. Afterward, a reference temperature is selected, and the isothermal measurements are shifted on a logarithmic time (or frequency) scale to form a so–called master curve.\n",
    "  \n",
    "  ![TTSP](figures/TTSP_small.png)\n",
    "  \n",
    "  Time-temperature shift factors, $a_{\\mathrm{T}}(\\theta)$, are defined as the horizontal shift that must be applied to individual measurements at a constant temperature, $\\theta_i$, to form the master curve at the reference temperature, $\\theta_{\\mathrm{ref}}$.\n",
    "  \n",
    "  The determined shift factors, $a_{\\mathrm{T}}$, are used to define a shift function that describes the temperature dependence of the viscoelastic material. Different shift functions for various materials are available in the literature. A commonly used shift function is the the [Williams-Landel-Ferry (WLF)](https://en.wikipedia.org/wiki/Williams%E2%80%93Landel%E2%80%93Ferry_equation),\n",
    "  \n",
    "  \\begin{equation}\n",
    "  \\log(a_{\\mathrm{T}}) = -\\frac{C_1\\left(\\theta-\\theta_{\\mathrm{ref}}\\right)}{C_2 + \\left(\\theta-\\theta_{\\mathrm{ref}}\\right)}\n",
    "  \\label{eq:WLF_shift}\n",
    "  \\end{equation}\n",
    "  \n",
    "  where $\\theta_{\\mathrm{ref}}$ is the reference temperature of the master curve. $\\theta$ is the temperature of interest, and $C_1$ and $C_2$ are calibration constants.  The TTSP is based on the kinetic theory of polymers, which is strictly speaking only valid above the glass transition temperature, $\\theta_g$. Although the TTSP is thought to be valid also for temperatures below $\\theta_g$, the exact lower limit is not well defined, and the principle is commonly applied to temperatures below $\\theta_g$ as long as the measurement data are shiftable to form a smooth master curve. Alternatively, different shift functions can be fitted. Below we provide a routine to fit polynomial shift function up to degree four."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "\n",
    "import LinViscoFit as visco\n",
    "#import ipywidgets as widgets\n",
    "\n",
    "#import pandas as pd\n",
    "#import io\n",
    "#import os\n",
    "\n",
    "#from IPython.display import display, clear_output, HTML\n",
    "#from base64 import b64encode\n",
    "#import matplotlib.pyplot as plt\n",
    "#pd.set_option('display.float_format', '{:.5e}'.format)\n",
    "\n",
    "visco.format_fig()\n",
    "GUI = visco.GUIControl()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Parameter identification\n",
    "\n",
    "The linear viscoelastic curve fitting routine in this notebook allows for experimental data in both the time and frequency domains. The following conventions are used within this notebook:\n",
    "\n",
    "| Physical quantity      | Symbol          | Variable   | Unit   |\n",
    "| :--------------------- | :-------------: | :--------- | :----: |\n",
    "| Relaxation modulus:    | $E(t)$          | `E_relax`  | MPa    |\n",
    "| Storage modulus:       | $E'(\\omega)$    | `E_stor`   | MPa    |\n",
    "| Loss modulus:          | $E''(\\omega)$   | `E_loss`   | MPa    |\n",
    "| Complex modulus:       | $|E^{\\ast}|$    | `E_comp`   | MPa    |\n",
    "| Loss modulus:          | $\\tan(\\delta)$  | `tan_del`  | -      |\n",
    "| Instantaneous modulus: | $E_0$           | `E_0`      | MPa    |\n",
    "| Equilibrium modulus:   | $E_{inf}$       | `E_inf`    | MPa    |\n",
    "| Angular frequency:     | $\\omega$        | `omega`    | rad/s  |\n",
    "| Frequency:             | $f$             | `f`        | 1/s    |\n",
    "| Time:                  | $t$             | `t`        | s      |\n",
    "| Temperature:           | $\\theta$        | `T`        | °C     |\n",
    "\n",
    "\n",
    "### Specify and upload input data\n",
    "\n",
    "#### Domain\n",
    "This notebook allows for the estimation of Prony series parameters used in a Generalized Maxwell model to describe the linear viscoelastic behavior of polymer materials. The parameters can be either fitted from measurement data of Dynamic mechanical thermal analysis (DMTA) in the frequency domain (freq) or from relaxation experiments in the time domain (time). \n",
    "\n",
    "#### Instrument\n",
    "DMTA measurements conducted with a Netzsch Gabo DMA EPLEXOR (Eplexor) can be directly uploaded in this notebook as Excel files. Use the `Excel Export!` feature of the Eplexor software with the default template to create the input files. For measurements conducted with other instruments choose the user option (user) and preprocess the input files to be provided in comma-separated values (csv) format with the following columns header:\n",
    "* **Frequency domain:** header = `f, E_stor, E_loss`, where `f` is the frequency in Hertz (Hz), and ```E_stor``` and `E_loss` are the storage and loss modulus in Megapascal (MPa), respectively.\n",
    "* **Time domain:** header = `t, E_relax`, where `t` is the time in seconds (s), and `E_relax` is the relaxation modulus in MPa.\n",
    "\n",
    "#### Type\n",
    "The data can be provided as measurement sets at different temperatures (raw) or as master curve obtained from time-temperature superposition (master). If measurements at different temperatures are provided (raw) the individual temperature sets need to be identified. \n",
    "* **Eplexor** The notebook identifies the corresponding temperature sets automatically (only available in the frequency domain).\n",
    "* **user** Two additional columns are necessary in the input file. One column indicating the temperature `T` of the measurement sets and one column with the header `Set` to identify the measurement sets. All measurements at the same temperature set are marked with the same number, e.g. 0 for all measurements in the the first temperature set. The first tempeature set (0) represents the coldest temperature followed by the second set (1) at the next higher temperature level and so forth (see the provided example input files for further details).\n",
    "\n",
    "#### Example input files\n",
    "A set of example input files is provided in a GitHub repository.\n",
    "[Link to example input files](https://github.com/martin-springer/LinViscoFit/tree/main/examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2d9dd784c1640a990a52586aefc67fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(RadioButtons(description='Domain:', layout=Layout(height='auto', width='auto'), options=('freq'…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(GUI.w_inp_gen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reference temperature \n",
    "\n",
    "Reference temperature refers to the temperature for which the master curve has been created through time-temperature superpostion. \n",
    "\n",
    "If a master curve from the Eplexor software is provided the reference temperature will be automatically extracted. \n",
    "\n",
    "For all other options please provide either the reference temperature of the user-specified master curve or the desired reference temperature for the time-temperature superposition of the raw data (for raw data the desired reference temperature will be automatically adjusted to align with the closest provided temperature set of the measurement input file).\n",
    "\n",
    "#### Optional shift factor upload\n",
    "If master curves are provided, the shift factor upload is optional and allows for the calculation of polynomial (D1 to D4) shift functions and the Williams–Landel–Ferry (WLF) shift function, but is not required for the Prony series estimation. \n",
    "\n",
    "If a master curve from created by the Eplexor software is provided, the default behavior of the notebook is to use the WLF shift function from the Eplexor software. However, in the time-temperature superpostion section, a checkbox is provided to overwrite the WLF fit of the Eplexor software and conduct another WLF fit with the algorithm in this notebook, which is then used to estimate the Prony series parameters.\n",
    "\n",
    "If raw measurement data are provided (for both Eplexor or user), the shift factors can be either determined for the desired reference temperature in the time-temperature superposition section or user-specified shift factors can be uploaded to be used to create the master curve. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f93599d195140d0a08b5036f47835e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatText(value=0.0, description='Reference temperature (C):', layout=Layout(height='auto', wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(GUI.w_inp_shift)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load and check the provided input files\n",
    "\n",
    "Once all the input parameter are specified and the necessary files are uploaded click the *Load data* button below. If the input files could be loaded successfully, the widgets will indicate the state of the uploaded data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a3fe0b223354e38b55843322c945599",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Button(button_style='success', description='Load data', layout=Layout(height='au…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(GUI.w_inp_load)\n",
    "#display(GUI.w_inp_check)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### Time-temperature superposition (shift functions)\n",
    "\n",
    "This section allows to calulate shift factors from raw input data and fit shift functions.\n",
    "\n",
    "#### Shift factors $\\log(a_{T})$ - Create master curve from raw input\n",
    "\n",
    "This subsection only applies if raw input data have been provided. If master curves have been uploaded, please procede to the next step. \n",
    "\n",
    "Here, the time-temperature superposition principle is applied to create a master curve from the individual temperature measurement sets provided in the raw input data file. If user shift factors, $\\log(a_{T})$, are uploaded, the provided shift factors will be used to create the master curve from the raw measurement sets at different temperatures (the checkbox allows you to overwrite the provided shift factors). If no shift factors are provided, the measurement sets from the raw input file are used to estimate the shift factors and create a master curve. Measurement sets below the desired reference temperatures are shifted to lower frequencies (longer time periods), whereas measurement sets at temperatures higher than the reference temperature are shifted to higher frequencies (shorter time periods). For the frequency domain, only the storage modulus input data are considered to create the master curve from the raw input data. The shift factors obtained from creating the storage modulus master curve are then used to create the loss modulus master curve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c9f429423154bc59dcb9a08cedaeae7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Button(button_style='info', description='master raw data', disabled=True, layout…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(GUI.w_aT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Shift functions (WLF & Polynomial degree 1 to 4)\n",
    "\n",
    "If shift factors are available, the WLF shift function and polynomial functions of degree 1 to 4 can be fitted and plotted below. If the WLF shift functions was already provided by the Eplexor software, the checkbox below let's you overwrite the WLF fit of the Eplexor software with a WLF fit of this notebook. Either way, both solutions should be very similar. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be4b82379c1f4559baea75d9c22ab9b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Button(button_style='info', description='(fit) & plot shift functions', disabled…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(GUI.w_shift)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### Estimate Prony series parameters\n",
    "\n",
    "#### Pre-process (smooth) master curve\n",
    "\n",
    "A moving median filter to remove outliers in the measurement data can be applied before the Prony series parameters are identified. The window size (win) can be adjusted through the slider above the figure. A window size of 1 means that no filtering procedure is performed and the raw data are fitted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd662f7eec444f1b8cdeb57398111c5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(button_style='info', description='smooth master curve', layout=Layout(height='auto', width='200px'), st…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "905f99f77c014d4486dfb7e01edfa543",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(GUI.b_smooth)\n",
    "display(GUI.out_smooth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define the number and discretization of the Prony series\n",
    "\n",
    "The number of Prony terms, $N$, needs to be defined before the parameter $\\tau_i$ and $\\alpha_i$ can be identified. The default behavior is to equally space one Prony term per decade along the logarithmic time axis, $\\tau_i$ = [1E-1, 1E0, 1E1,...] (s), within the experimental window. This discretization typically delivers accurate results for engineering applications. However, the fine discretization can be computationally heavy for usage in Finite Element simulations. Hence, we allow the user to modify this default discretization by either using the optimization routine provided below or by manually defining the number of Prony terms $N$ for the discretization. Additionally, the user can decide wether to round the lowest and highest relaxation times, $\\tau_i$, to the nearest base 10 number within the measurement window (round) or to use the exact minimum and maximum values of the experimental window for the relaxation times (exact). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b137d43f4564f82a68a56245afb156b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(RadioButtons(description='Discretization:', layout=Layout(height='auto', width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(GUI.w_dis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Curve fitting\n",
    "\n",
    "Two different curve fitting routines for the Prony series parameters are employed and are dependent on the domain of the input data:\n",
    "\n",
    "* **Frequency domain**: A generalized collocation method using stiffness matrices is used as described in [Kraus, M. A., and M. Niederwald. Eur J Eng Mech 37.1 (2017): 82-106](https://journals.ub.ovgu.de/index.php/techmech/article/view/600). This methods utilizes both the storage and loss modulus master curves to estimate the Prony series parameters.\n",
    "   \n",
    "   \n",
    "* **Time domain**: A nonlinear least-squares optimization is performed with the L-BFGS-B algorithm of the scipy package. The implementation is similar to the optimization problem described by [Barrientos, E., Pelayo, F., Noriega, Á. et al. Mech Time-Depend Mater 23, 193–206 (2019)](https://doi.org/10.1007/s11043-018-9394-z) for a homogenous distribution of discrete times. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4860ad009444829b12b2c9578b40711",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(button_style='danger', description='fit Prony series', layout=Layout(height='auto', width='200px'), sty…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "694a9be5b0ce4a3bb54ccf1d9f642b42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(GUI.b_fit)\n",
    "display(GUI.out_fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### Generalized Maxwell model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(GUI.b_GMaxw)\n",
    "display(GUI.out_GMaxw)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### Download results and figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(GUI.db_zip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#old\n",
    "display(GUI.db_prony)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### Start over"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(GUI.b_reload)\n",
    "display(GUI.out_html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimization - TBD"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#Optimization draft - time domain\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "\n",
    "def E_relax(time, alpha_i, tau_i, E_0):\n",
    "    #return E_0 * (1-np.dot(alpha_i, 1-np.exp(-time/tau_i[:,None])))\n",
    "    return 1-np.dot(alpha_i, 1-np.exp(-time/tau_i[:,None]))\n",
    "    \n",
    "    #y = np.zeros(time.shape[0])\n",
    "    #for i, t in enumerate(time):\n",
    "    #    y[i] = E_0 * (1 - np.sum(alpha_i*(1-np.exp(-t/tau_i))))\n",
    "    #return y\n",
    "\n",
    "\n",
    "def residual(alpha_i, tau_i, E_0, E_relax_meas, time_meas):\n",
    "    #return np.sum((1 - E_relax(time_meas, alpha_i, tau_i, E_0)/E_relax_meas)**2)\n",
    "    return np.sum((E_relax_meas - E_relax(time_meas, alpha_i, tau_i, E_0))**2)\n",
    "\n",
    "def residual_tau(tau_i, alpha_i, E_0, E_relax_meas, time_meas):\n",
    "    #return np.sum((1 - E_relax(time_meas, alpha_i, tau_i, E_0)/E_relax_meas)**2)\n",
    "    return np.sum((E_relax_meas - E_relax(time_meas, alpha_i, tau_i, E_0))**2)\n",
    "\n",
    "def fit_prony_time_alpha(df_dis, df_master, alpha_i, tau_i):\n",
    "\n",
    "    #alpha_i = np.ones(df_dis['tau'].values.shape) #start all a_i = 1\n",
    "    #tau_i = df_dis['tau'].values\n",
    "    E_0 = df_dis.E_0\n",
    "    E_relax_meas = df_master['E_relax_filt'].values / E_0\n",
    "    time_meas = df_master['t'].values\n",
    "    N = df_dis.nprony\n",
    "    bnd = ((0,1),)*alpha_i.shape[0]\n",
    "\n",
    "    res = minimize(residual, alpha_i, args=(tau_i, E_0, E_relax_meas, time_meas), method='L-BFGS-B', bounds=bnd)\n",
    "    \n",
    "    #print(res)\n",
    "    \n",
    "    alpha = res.x\n",
    "\n",
    "    df = pd.DataFrame()\n",
    "    \n",
    "    #Ensure that Sum(alpha_i) < 1 (otherwise can lead to numerical difficulties in FEM)\n",
    "    if alpha.sum() >= 1:\n",
    "        df['alpha'] = 0.99/alpha.sum()*alpha #Normalize alpha values to 0.99\n",
    "    else:\n",
    "        df['alpha'] = alpha\n",
    "        \n",
    "    df['tau'] = tau_i\n",
    "\n",
    "    df_prony = df[['tau', 'alpha']].copy()\n",
    "    df_prony = df_prony.iloc[::-1].reset_index(drop=True)\n",
    "    df_prony.index += 1 \n",
    "    df_prony.RefT = df_dis.RefT\n",
    "\n",
    "    #Prepare input arguments for generalized Maxwell model\n",
    "    f_min = df_dis['f'].iloc[0]\n",
    "    f_max = df_dis['f'].iloc[-1]\n",
    "\n",
    "    prony = {'E_0':E_0, 'df_terms':df_prony, 'f_min':f_min, 'f_max':f_max, 'label':'equi.'}\n",
    "    \n",
    "    return prony\n",
    "\n",
    "def fit_prony_time_tau(df_dis, df_master, tau_i, alpha_i):\n",
    "\n",
    "    #print(tau_i)\n",
    "    E_0 = df_dis.E_0\n",
    "    E_relax_meas = df_master['E_relax_filt'].values / E_0\n",
    "    time_meas = df_master['t'].values\n",
    "    N = df_dis.nprony\n",
    "    #bnd = ((0,1),)*alpha_i.shape[0]\n",
    "    \n",
    "    f_min = GUI.df_dis['f'].iloc[0]\n",
    "    f_max = GUI.df_dis['f'].iloc[-1]\n",
    "\n",
    "    tau_max = 1/(2*np.pi*f_min)\n",
    "    tau_min = 1/(2*np.pi*f_max)\n",
    "\n",
    "    bnd_min = 10**(np.log10(tau_i)-1)\n",
    "    bnd_min[0] = tau_min\n",
    "    bnd_max = 10**(np.log10(tau_i)+1)\n",
    "    bnd_max[-1] = tau_max\n",
    "    bnd = tuple(zip(bnd_min, bnd_max))\n",
    "\n",
    "    res = minimize(residual_tau, tau_i, args=(alpha_i, E_0, E_relax_meas, time_meas), method='L-BFGS-B' , bounds=bnd) #\n",
    "    \n",
    "    #print(res)\n",
    "    \n",
    "    tau = res.x\n",
    "    \n",
    "    df = pd.DataFrame()\n",
    "    df['tau'] = tau\n",
    "    df['alpha'] = alpha_i\n",
    "\n",
    "    #Ensure that Sum(alpha_i) < 1 (otherwise can lead to numerical difficulties in FEM)\n",
    "    #if alpha.sum() >= 1:\n",
    "    #    df_dis['alpha'] = 0.99/alpha.sum()*alpha #Normalize alpha values to 0.99\n",
    "    #else:\n",
    "    #    df_dis['alpha'] = alpha\n",
    "\n",
    "    df_prony = df[['tau', 'alpha']].copy()\n",
    "    df_prony = df_prony.iloc[::-1].reset_index(drop=True)\n",
    "    df_prony.index += 1 \n",
    "    df_prony.RefT = df_dis.RefT\n",
    "\n",
    "    #Prepare input arguments for generalized Maxwell model\n",
    "    f_min = df_dis['f'].iloc[0]\n",
    "    f_max = df_dis['f'].iloc[-1]\n",
    "\n",
    "    prony = {'E_0':E_0, 'df_terms':df_prony, 'f_min':f_min, 'f_max':f_max, 'label':'equi.'}\n",
    "    \n",
    "    return prony"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "prony = GUI.prony\n",
    "\n",
    "for i in range(20):\n",
    "\n",
    "    tau_i = prony['df_terms']['tau'].values\n",
    "    alpha_i = prony['df_terms']['alpha'].values\n",
    "    prony = fit_prony_time_alpha(GUI.df_dis, GUI.df_master, alpha_i, tau_i)\n",
    "    \n",
    "    prony['df_terms'] = prony['df_terms'].drop(prony['df_terms']['alpha'].idxmin()) #.iloc[1:-1]\n",
    "    \n",
    "    tau_i = prony['df_terms']['tau'].values\n",
    "    alpha_i = prony['df_terms']['alpha'].values\n",
    "    prony = fit_prony_time_tau(GUI.df_dis, GUI.df_master, tau_i, alpha_i)\n",
    "    \n",
    "    df_GMaxw = visco.calc_GenMaxw(**prony)\n",
    "    visco.plot_fit(GUI.df_master, df_GMaxw);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Verification - Compare with Ansys"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#Eplexor raw\n",
    "#epl_raw = visco.load_file('Eplexor_Input\\\\T150_tfs_raw.xls')\n",
    "\n",
    "#df_raw = visco.load_Eplexor_raw(epl_raw)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#Eplexor master\n",
    "#epl = visco.load_file('Eplexor_Input\\\\T150_tfs_master.xls')\n",
    "\n",
    "#df_master, df_aT, df_WLF, df_master_raw = visco.load_Eplexor_master(epl)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#Load user master\n",
    "data = visco.load_file('..\\\\..\\\\Verification\\\\ANSYS_Frequency\\\\freq_user_master.csv')\n",
    "shift = visco.load_file('..\\\\..\\\\Verification\\\\ANSYS_Frequency\\\\shift_factors.csv')\n",
    "RefT = -5\n",
    "domain = 'freq'\n",
    "df_master = visco.load_user_master(data, domain, RefT)\n",
    "df_aT = visco.load_user_shift(shift)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#Shift function\n",
    "df_WLF = visco.fit_shift_WLF(df_master.RefT, df_aT)\n",
    "df_poly = visco.fit_shift_poly(df_aT)\n",
    "\n",
    "fig_shift, df_shift = visco.plot_shift_func(df_aT, df_WLF, df_poly)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#Smooth\n",
    "win = 5\n",
    "df_master = visco.smooth(df_master, win)\n",
    "fig_smooth = visco.plot_smooth(df_master)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#Discretization\n",
    "\n",
    "df_dis = visco.discretize(df_master)\n",
    "fig_dis = visco.plot_dis(df_master, df_dis)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#Prony fit\n",
    "\n",
    "if domain == 'freq':\n",
    "    prony = visco.fit_prony_freq(df_dis)\n",
    "elif domain == 'time':\n",
    "    prony = visco.fit_prony_time(df_dis, df_master)\n",
    "\n",
    "df_GMaxw = visco.calc_GenMaxw(**prony)\n",
    "fig_fit = visco.plot_fit(df_master, df_GMaxw)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#Gen. Maxwell\n",
    "fig_GMaxw = visco.plot_GMaxw(df_GMaxw);"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#Comparison ANSYS\n",
    "\n",
    "df_prony_ANSYS = visco.load_prony_ANSYS('..\\\\..\\\\Verification\\\\ANSYS_Frequency\\\\prony_terms.MPL')\n",
    "prony_ANSYS = visco.prep_prony_ANSYS(df_prony_ANSYS, prony)\n",
    "df_GMaxw_ANSYS = visco.calc_GenMaxw(**prony_ANSYS)\n",
    "fig_fit_ANSYS = visco.plot_fit_ANSYS(df_master, df_GMaxw, df_GMaxw_ANSYS)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "fig_prony_coeff = visco.plot_prony_coeff([prony, prony_ANSYS])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "## Optimization of number of prony terms"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "prony_opt = visco.optimize(prony)\n",
    "fig = visco.plot_prony_coeff([prony, prony_opt])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "df_GMaxw_opt = visco.calc_GenMaxw(**prony_opt)\n",
    "fig = visco.plot_fit(df_master, df_GMaxw_opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "voila": {
   "template": "classic"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
